name: Update Law Data

on:
  schedule:
    - cron: '0 23 * * *'  # 毎日午前8時（JST）- 日次増分更新
  workflow_dispatch:
    inputs:
      lookback_days:
        description: 'e-Gov APIの遡り日数（デフォルト30日）'
        required: false
        default: '30'

jobs:
  update-data:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}

    - uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: pip install beautifulsoup4 requests lxml feedparser

    - name: Create data directory
      run: mkdir -p public/data

    - name: Run scraper (merge mode)
      run: |
        python scraper.py
        echo "Scraper completed"

    - name: Verify output
      run: |
        if [ -f "public/data/revisions.json" ]; then
          ITEM_COUNT=$(python3 -c "import json; data=json.load(open('public/data/revisions.json')); print(len(data))")
          echo "revisions.json: ${ITEM_COUNT} items"
        else
          echo "ERROR: revisions.json not found"
          exit 1
        fi

    - name: Commit changes
      run: |
        git config user.name 'github-actions[bot]'
        git config user.email 'github-actions[bot]@users.noreply.github.com'

        git add -f public/data/revisions.json

        if git diff --staged --quiet; then
          echo "No changes detected"
        else
          ITEM_COUNT=$(python3 -c "import json; data=json.load(open('public/data/revisions.json')); print(len(data))")
          git commit -m "bot: daily update (${ITEM_COUNT} items) $(date +'%Y-%m-%d')"
          git push
          echo "Data updated"
        fi

    - uses: actions/upload-artifact@v4
      if: always()
      with:
        name: law-data
        path: public/data/revisions.json
        retention-days: 7
